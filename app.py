import streamlit as st
import sqlite3
import pandas as pd
from io import StringIO
import requests
from scanner import scan_website
from db import save_scan_results, initialize_db

def is_valid_url(url):
    # Check if the URL starts with 'http://' or 'https://'
    if not (url.startswith("http://") or url.startswith("https://")):
        return False
    # Check if the URL is accessible
    try:
        response = requests.get(url, timeout=5)
        return response.status_code == 200
    except requests.RequestException:
        return False

def export_to_csv(df, filename):
    csv = df.to_csv(index=False)
    st.download_button(
        label="Download CSV",
        data=csv,
        file_name=filename,
        mime='text/csv'
    )

def main():
    st.title('Web Vulnerability Scanner')

    # Initialize database
    initialize_db()

    # Scan Page
    st.header('Start New Scan')
    url = st.text_input('Enter URL to Scan', '')
    vulnerabilities = st.multiselect(
        'Select Vulnerabilities to Check',
        ['SQL Injection', 'XSS', 'CSRF', 'IDOR', 'Security Misconfigurations',
         'Authentication Issues', 'Sensitive Data Exposure', 'Cryptographic Storage',
         'Broken Access Control', 'Unvalidated Redirects']
    )
    if st.button('Start Scan'):
        if url and vulnerabilities:
            if not is_valid_url(url):
                st.error('Please provide a working URL that starts with "http://" or "https://" and is accessible.')
            else:
                with st.spinner('Scanning in progress...'):
                    results = scan_website(url, vulnerabilities)
                    
                    st.write('### Scan Results:')
                    
                    # Display detailed scan results in expandable sections
                    for vuln, result in results.items():
                        with st.expander(f'**{vuln}**'):
                            if isinstance(result, list) and result:
                                for r in result:
                                    st.write(f'- {r}')
                            else:
                                st.write(f'- {result}')
                    
                    save_scan_results(url, results)
                    st.success('Scan completed and results saved!')

                    # Provide export option for scan results
                    results_df = pd.DataFrame({
                        'Vulnerability': list(results.keys()),
                        'Details': [', '.join(val) if isinstance(val, list) else val for val in results.values()]
                    })
                    export_to_csv(results_df, 'scan_results.csv')

        else:
            st.error('Please provide a URL and select vulnerabilities to scan.')

    # History Page
    st.header('Scan History')
    
    # Load scan history
    conn = sqlite3.connect('scan_history.db')
    c = conn.cursor()
    
    # Search and filter options
    search_query = st.text_input('Search by URL', '')
    date_filter = st.date_input('Filter by Date', None)
    
    query = 'SELECT * FROM scans WHERE 1=1'
    params = []
    
    if search_query:
        query += ' AND url LIKE ?'
        params.append(f'%{search_query}%')
    
    if date_filter:
        query += ' AND date LIKE ?'
        params.append(f'{date_filter:%Y-%m-%d}%')
    
    c.execute(query, params)
    rows = c.fetchall()
    
    if rows:
        st.write('### Scan History')
        df = pd.DataFrame(rows, columns=['Date', 'URL', 'Results'])
        
        # Pagination
        page_size = st.slider('Select page size', min_value=5, max_value=50, value=10)
        max_page_number = max(1, (len(df) // page_size) + 1)
        page_number = st.slider('Select page number', min_value=1, max_value=max_page_number, value=1)
        
        # Display data based on pagination
        start_row = (page_number - 1) * page_size
        end_row = min(start_row + page_size, len(df))  # Ensure end_row doesn't exceed DataFrame length
        
        st.write(df.iloc[start_row:end_row])
        
        # Export history option
        export_to_csv(df, 'scan_history.csv')
    else:
        st.write('No scan history found.')

if __name__ == '__main__':
    main()
